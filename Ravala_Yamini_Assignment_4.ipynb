{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaminiravala/5731/blob/main/Ravala_Yamini_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "(1) Features (text representation) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuFPKhC0m1fd"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFlmHB5jYiPD"
      },
      "outputs": [],
      "source": [
        "file_path = 'srmtd_reviews_cleaned.xl (1).xls'\n",
        "data = pd.read_excel(file_path)\n",
        "documents = data['Cleaned_Review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYrcyqxgYiPD",
        "outputId": "3be5a23e-72ab-4114-fa01-358e8f2ff92f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  'harsha babu nice performance story love help charuseela millionaire fall'),\n",
              " (1, 'film acting hero flop routine time movie expecting got review'),\n",
              " (2,\n",
              "  'movie time character great babu like action rajendraprasad decent worked'),\n",
              " (3,\n",
              "  'rating telugu multimillionaire different charusheela movie story adopts directed review'),\n",
              " (4,\n",
              "  'good performance film india job dancer especially wonder commercial mahesh'),\n",
              " (5, 'content new formula dont routine different director movie story good'),\n",
              " (6, 'village vardhan come people babu rest harsha know father son'),\n",
              " (7, 'wasted said new story mahesh movie sruthi routine siva usual'),\n",
              " (8, 'film dont know good movie audience bit flop telugu great'),\n",
              " (9, 'people babu form bit needy process instead life family ravikanth')]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Text Representation using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
        "# LDA Model\n",
        "n_topics = 10\n",
        "lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
        "lda.fit(tfidf)\n",
        "# Display the top words in each topic\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    topic_summaries = []\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        topic_top_words = \" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
        "        topic_summaries.append((topic_idx, topic_top_words))\n",
        "    return topic_summaries\n",
        "\n",
        "no_top_words = 10\n",
        "topic_summaries = display_topics(lda, tfidf_vectorizer.get_feature_names_out(), no_top_words)\n",
        "# Display\n",
        "topic_summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vATjQNTY8buA"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls3WQqCJYiPF"
      },
      "outputs": [],
      "source": [
        "# Data Cleaning\n",
        "cleaned_data = data.dropna(subset=['Cleaned_Review', 'Sentiment'])\n",
        "X = cleaned_data['Cleaned_Review']\n",
        "y = cleaned_data['Sentiment'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBGHwCqcYiPF"
      },
      "outputs": [],
      "source": [
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyEbpTtqYiPF"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8LUy7rVYiPF",
        "outputId": "27adc16b-585d-4628-82c8-92f57aa12175"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "363B76PQYiPF",
        "outputId": "16f99c8c-c213-4df7-cd59-d3011a85691d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.25,\n",
              " '              precision    recall  f1-score   support\\n\\n    negative       0.00      0.00      0.00         2\\n     neutral       0.00      0.00      0.00         4\\n    positive       0.25      1.00      0.40         2\\n\\n    accuracy                           0.25         8\\n   macro avg       0.08      0.33      0.13         8\\nweighted avg       0.06      0.25      0.10         8\\n')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluation\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "accuracy, report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dZEQs7PYiPF"
      },
      "outputs": [],
      "source": [
        "# model for comparison\n",
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "svm_model = SVC()\n",
        "cv_folds = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uTTD2ARYiPF",
        "outputId": "5955c419-a1b8-4b4b-9c80-c46c931fb175"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/saicharanreddypotluri/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "scoring_metrics_standard = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        "logistic_cv_results_standard = cross_validate(logistic_model, X_train_tfidf, y_train, cv=cv_folds,\n",
        "                                              scoring=scoring_metrics_standard)\n",
        "svm_cv_results_standard = cross_validate(svm_model, X_train_tfidf, y_train, cv=cv_folds,\n",
        "                                         scoring=scoring_metrics_standard)\n",
        "\n",
        "def average_cv_results_standard(cv_results):\n",
        "    return {metric: np.mean(cv_results[f'test_{metric}']) for metric in scoring_metrics_standard}\n",
        "\n",
        "logistic_performance_standard = average_cv_results_standard(logistic_cv_results_standard)\n",
        "svm_performance_standard = average_cv_results_standard(svm_cv_results_standard)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAYwiMszYiPG",
        "outputId": "afc0c1f3-9585-4539-a62d-2e11f98555f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'accuracy': 0.6333333333333332,\n",
              "  'precision_macro': 0.29999999999999993,\n",
              "  'recall_macro': 0.4666666666666666,\n",
              "  'f1_macro': 0.3644444444444444},\n",
              " {'accuracy': 0.6333333333333332,\n",
              "  'precision_macro': 0.29999999999999993,\n",
              "  'recall_macro': 0.4666666666666666,\n",
              "  'f1_macro': 0.3644444444444444})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logistic_performance_standard, svm_performance_standard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(20 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfvMKJjIXS5G",
        "outputId": "1922a51c-e075-4896-dbb0-16cbe6fbf3d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              " 0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              " 1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              " 2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              " 3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              " 4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              " \n",
              "   LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              " 0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              " 1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              " 2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              " 3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              " 4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              " \n",
              "   YrSold  SaleType  SaleCondition  SalePrice  \n",
              " 0   2008        WD         Normal     208500  \n",
              " 1   2007        WD         Normal     181500  \n",
              " 2   2008        WD         Normal     223500  \n",
              " 3   2006        WD        Abnorml     140000  \n",
              " 4   2008        WD         Normal     250000  \n",
              " \n",
              " [5 rows x 81 columns],\n",
              " (1460, 81),\n",
              " (1459, 80))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "\n",
        "train_file_path = 'assignment4-question3-data (1)/train.csv'\n",
        "test_file_path = 'assignment4-question3-data (1)/test.csv'\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "train_data.head(), train_data.shape, test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1GIrl1_YiPG"
      },
      "outputs": [],
      "source": [
        "# filling missing values\n",
        "def fill_missing_values(df, fill_strategy):\n",
        "    for column, strategy in fill_strategy.items():\n",
        "        if strategy == 'mean':\n",
        "            df[column].fillna(df[column].mean(), inplace=True)\n",
        "        elif strategy == 'median':\n",
        "            df[column].fillna(df[column].median(), inplace=True)\n",
        "        elif strategy == 'mode':\n",
        "            df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "        elif strategy == 'none':\n",
        "            df[column].fillna('None', inplace=True)\n",
        "        elif strategy == 'drop':\n",
        "            df.drop(column, axis=1, inplace=True)\n",
        "\n",
        "# define strategies\n",
        "fill_strategies_train = {\n",
        "    'LotFrontage': 'mean',\n",
        "    'Alley': 'none',\n",
        "    'MasVnrType': 'mode',\n",
        "    'MasVnrArea': 'mean',\n",
        "    'BsmtQual': 'mode',\n",
        "    'FireplaceQu': 'none',\n",
        "    'GarageType': 'mode',\n",
        "    'GarageYrBlt': 'mean',\n",
        "    'PoolQC': 'none',\n",
        "    'Fence': 'none',\n",
        "    'MiscFeature': 'none',\n",
        "}\n",
        "\n",
        "fill_strategies_test = fill_strategies_train.copy()\n",
        "fill_strategies_test.update({\n",
        "\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogvgKYTwYiPG"
      },
      "outputs": [],
      "source": [
        "fill_missing_values(train_data, fill_strategies_train)\n",
        "fill_missing_values(test_data, fill_strategies_test)\n",
        "# verifying\n",
        "missing_values_train_after = train_data.isnull().sum().sum()\n",
        "missing_values_test_after = test_data.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Vivnra8YiPG",
        "outputId": "ebf4bb35-8f3e-4bbd-9772-740fd0cedd43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(394, 429)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "missing_values_train_after, missing_values_test_after"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BbswDvnEX-k"
      },
      "source": [
        "# **Question 4: Using Pre-trained LLMs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKwKTnW1EX-k"
      },
      "source": [
        "(20 points)\n",
        "Utilize a **pre-trained Large Language Model (LLM) from the Hugging Face Repository** for your specific task using the data collected in Assignment 3. After creating an account on Hugging Face (https://huggingface.co/), choose a relevant LLM from their repository, such as GPT-3, BERT, or RoBERTa or any Meta based text analysis model. Provide a brief description of the selected LLM, including its original sources, significant parameters, and any task-specific fine-tuning if applied.\n",
        "\n",
        "Perform a detailed analysis of the LLM's performance on your task, including key metrics, strengths, and limitations. Additionally, discuss any challenges encountered during the implementation and potential strategies for improvement. This will enable a comprehensive understanding of the chosen LLM's applicability and effectiveness for the given task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJgHWnOhFm-C"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}